{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('BigData').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-UOVJTRMT.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BigData</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1c5e4263070>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Resumiendo y normalizando con StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Datos con PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('telco_customer_churn.csv',\n",
    "                    header=True, \n",
    "                    inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cat = [nC for nC,dt in df.dtypes if dt =='string']\n",
    "var_num = [nC for nC,dt in df.dtypes if dt in ['int','double']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cat.remove('customerID')\n",
    "var_cat.remove('Churn')\n",
    "var_cat.remove('TotalCharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiando la variable TotalCharges a double\n",
    "df = df.withColumn('TotalCharges', df['TotalCharges'].cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['TotalCharges'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar Nulls\n",
    "for col in df.columns:\n",
    "    cant = df.filter(df['TotalCharges'].isNull()).count()\n",
    "    print(col,cant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7043"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remover NA\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7032"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_num.append('TotalCharges')\n",
    "var_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'Partner',\n",
       " 'Dependents',\n",
       " 'PhoneService',\n",
       " 'MultipleLines',\n",
       " 'InternetService',\n",
       " 'OnlineSecurity',\n",
       " 'OnlineBackup',\n",
       " 'DeviceProtection',\n",
       " 'TechSupport',\n",
       " 'StreamingTV',\n",
       " 'StreamingMovies',\n",
       " 'Contract',\n",
       " 'PaperlessBilling',\n",
       " 'PaymentMethod']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento a las variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_etapas = []\n",
    "\n",
    "for cat in var_cat:\n",
    "    \n",
    "    strIdx = StringIndexer(inputCol=cat, outputCol=cat+'_index')\n",
    "    encoder = OneHotEncoder(inputCol=cat+'_index',outputCol=cat+'_oneHot')\n",
    "    lista_etapas += [strIdx,encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento a la variable cat Y (Churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx2 = StringIndexer(inputCol='Churn',outputCol='Y')\n",
    "lista_etapas.append(strIdx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniendo los vectores one-hot de las variables cat + variables num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnasVectores = [c+'_oneHot' for c in var_cat] + var_num\n",
    "\n",
    "ensamblador = VectorAssembler(inputCols=columnasVectores,outputCol='X')\n",
    "\n",
    "lista_etapas.append(ensamblador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando todas las variables del vector assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol='X',outputCol='X_scaled')\n",
    "lista_etapas.append(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_c40d17582262,\n",
       " OneHotEncoder_77e841302c47,\n",
       " StringIndexer_260464fdc83f,\n",
       " OneHotEncoder_3274f4dfd1c1,\n",
       " StringIndexer_63b8a9cee218,\n",
       " OneHotEncoder_94191060b518,\n",
       " StringIndexer_c058ff025585,\n",
       " OneHotEncoder_48d34774c573,\n",
       " StringIndexer_226b8c88dbc2,\n",
       " OneHotEncoder_c6bcd2c7d0c0,\n",
       " StringIndexer_8f22d3867922,\n",
       " OneHotEncoder_abae2342cb48,\n",
       " StringIndexer_19717e2cbc49,\n",
       " OneHotEncoder_9cdff7c1268d,\n",
       " StringIndexer_5ac21f087cbb,\n",
       " OneHotEncoder_46b4ecb5b2b1,\n",
       " StringIndexer_b17e566c9b7f,\n",
       " OneHotEncoder_e5065dbdc5d7,\n",
       " StringIndexer_dee85308c8e0,\n",
       " OneHotEncoder_962d6b3c2fdc,\n",
       " StringIndexer_0c0c207081c6,\n",
       " OneHotEncoder_dfad41c16e83,\n",
       " StringIndexer_3e7bfb1fec97,\n",
       " OneHotEncoder_cd942f7b39b1,\n",
       " StringIndexer_7a44eff67c29,\n",
       " OneHotEncoder_cfedafb2ef61,\n",
       " StringIndexer_a698b7ec40fd,\n",
       " OneHotEncoder_4d66281f4e67,\n",
       " StringIndexer_fd1dae86f8fa,\n",
       " OneHotEncoder_74a0c01e4b96,\n",
       " StringIndexer_9fab1281f99e,\n",
       " VectorAssembler_b977f23cf6fd,\n",
       " StandardScaler_cbeeb05e6a04]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando las etapas al dataset - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "procesadorEtapas = Pipeline(stages=lista_etapas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = procesadorEtapas.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = modelo.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_scaled</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.0, 2.1851748981300347, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.9999458781640924, 2.001082630964643, 2.1851...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.9999458781640924, 2.001082630964643, 2.1851...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.9999458781640924, 2.001082630964643, 2.1851...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 2.001082630964643, 2.1851748981300347, 3...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            X_scaled    Y\n",
       "0  (0.0, 0.0, 2.1851748981300347, 0.0, 0.0, 0.0, ...  0.0\n",
       "1  (1.9999458781640924, 2.001082630964643, 2.1851...  0.0\n",
       "2  (1.9999458781640924, 2.001082630964643, 2.1851...  1.0\n",
       "3  (1.9999458781640924, 2.001082630964643, 2.1851...  0.0\n",
       "4  (0.0, 2.001082630964643, 2.1851748981300347, 3...  1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.select(['X_scaled','Y']).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[SparseVector(30, {2: 2.1852, 7: 2.1056, 8: 1.9999, 11: 2.1037, 12: 2.0144, 14: 2.0, 16: 2.0416, 18: 2.045, 20: 2.0104, 22: 2.0352, 23: 2.1165, 27: 0.0407, 28: 0.9922, 29: 0.0132})],\n",
       "       [SparseVector(30, {0: 1.9999, 1: 2.0011, 2: 2.1852, 3: 3.3833, 4: 2.0012, 7: 2.1056, 9: 2.2115, 10: 2.0149, 13: 2.1051, 14: 2.0, 16: 2.0416, 18: 2.045, 24: 2.383, 27: 1.3852, 28: 1.8929, 29: 0.8336})],\n",
       "       [SparseVector(30, {0: 1.9999, 1: 2.0011, 2: 2.1852, 3: 3.3833, 4: 2.0012, 7: 2.1056, 9: 2.2115, 11: 2.1037, 12: 2.0144, 14: 2.0, 16: 2.0416, 18: 2.045, 20: 2.0104, 22: 2.0352, 24: 2.383, 27: 0.0815, 28: 1.7899, 29: 0.0477})],\n",
       "       ...,\n",
       "       [SparseVector(30, {7: 2.1056, 9: 2.2115, 10: 2.0149, 12: 2.0144, 14: 2.0, 16: 2.0416, 18: 2.045, 20: 2.0104, 22: 2.0352, 23: 2.1165, 27: 0.4482, 28: 0.9838, 29: 0.1528})],\n",
       "       [SparseVector(30, {0: 1.9999, 2: 2.1852, 3: 3.3833, 5: 2.0247, 6: 2.0143, 8: 1.9999, 10: 2.0149, 12: 2.0144, 14: 2.0, 16: 2.0416, 18: 2.045, 20: 2.0104, 22: 2.0352, 24: 2.383, 26: 2.7112, 27: 0.163, 28: 2.4729, 29: 0.1353})],\n",
       "       [SparseVector(30, {0: 1.9999, 1: 2.0011, 2: 2.1852, 3: 3.3833, 4: 2.0012, 6: 2.0143, 9: 2.2115, 10: 2.0149, 13: 2.1051, 15: 2.2034, 17: 2.0556, 19: 2.0516, 21: 2.3426, 22: 2.0352, 25: 2.4167, 27: 2.6889, 28: 3.5116, 29: 3.0195})]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.select(['X_scaled']).toPandas().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 5628\n",
      "Test Dataset Count: 1404\n"
     ]
    }
   ],
   "source": [
    "train, test = df2.randomSplit([0.8, 0.2], seed = 10)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'X_scaled', labelCol = 'Y')\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>Y</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003-MKNFE</td>\n",
       "      <td>[0.6846107139763482, -0.6846107139763482]</td>\n",
       "      <td>[0.6647669828639995, 0.3352330171360005]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0011-IGKFF</td>\n",
       "      <td>[-0.9121565436709589, 0.9121565436709589]</td>\n",
       "      <td>[0.28655874449363083, 0.7134412555063692]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013-SMEOE</td>\n",
       "      <td>[2.8875957665894108, -2.8875957665894108]</td>\n",
       "      <td>[0.9472298339525708, 0.052770166047429234]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0017-DINOC</td>\n",
       "      <td>[4.607000247694261, -4.607000247694261]</td>\n",
       "      <td>[0.990116933842407, 0.009883066157593046]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0019-EFAEP</td>\n",
       "      <td>[3.011427647321358, -3.011427647321358]</td>\n",
       "      <td>[0.9530877278961264, 0.04691227210387361]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID                              rawPrediction  \\\n",
       "0  0003-MKNFE  [0.6846107139763482, -0.6846107139763482]   \n",
       "1  0011-IGKFF  [-0.9121565436709589, 0.9121565436709589]   \n",
       "2  0013-SMEOE  [2.8875957665894108, -2.8875957665894108]   \n",
       "3  0017-DINOC    [4.607000247694261, -4.607000247694261]   \n",
       "4  0019-EFAEP    [3.011427647321358, -3.011427647321358]   \n",
       "\n",
       "                                  probability    Y  prediction  \n",
       "0    [0.6647669828639995, 0.3352330171360005]  0.0         0.0  \n",
       "1   [0.28655874449363083, 0.7134412555063692]  1.0         1.0  \n",
       "2  [0.9472298339525708, 0.052770166047429234]  0.0         0.0  \n",
       "3   [0.990116933842407, 0.009883066157593046]  0.0         0.0  \n",
       "4   [0.9530877278961264, 0.04691227210387361]  0.0         0.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.select(['customerID','rawPrediction','probability','Y','prediction']).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(lrModel.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.8428829717291296\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='Y')\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN - tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = KMeans(k = 2,featuresCol='X_scaled',predictionCol='Outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = modelo.fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = modelo.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_scaled</th>\n",
       "      <th>Y</th>\n",
       "      <th>Outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.0, 2.1851748981300347, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.9999458781640924, 2.001082630964643, 2.1851...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.9999458781640924, 2.001082630964643, 2.1851...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1.9999458781640924, 2.001082630964643, 2.1851...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 2.001082630964643, 2.1851748981300347, 3...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>(1.9999458781640924, 0.0, 0.0, 3.3832826290967...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>(0.0, 0.0, 0.0, 3.3832826290967626, 0.0, 2.024...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.10555511...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>(1.9999458781640924, 0.0, 2.1851748981300347, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>(1.9999458781640924, 2.001082630964643, 2.1851...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7032 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               X_scaled    Y  Outputs\n",
       "0     (0.0, 0.0, 2.1851748981300347, 0.0, 0.0, 0.0, ...  0.0        1\n",
       "1     (1.9999458781640924, 2.001082630964643, 2.1851...  0.0        1\n",
       "2     (1.9999458781640924, 2.001082630964643, 2.1851...  1.0        1\n",
       "3     (1.9999458781640924, 2.001082630964643, 2.1851...  0.0        1\n",
       "4     (0.0, 2.001082630964643, 2.1851748981300347, 3...  1.0        1\n",
       "...                                                 ...  ...      ...\n",
       "7027  (1.9999458781640924, 0.0, 0.0, 3.3832826290967...  0.0        0\n",
       "7028  (0.0, 0.0, 0.0, 3.3832826290967626, 0.0, 2.024...  0.0        0\n",
       "7029  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.10555511...  0.0        1\n",
       "7030  (1.9999458781640924, 0.0, 2.1851748981300347, ...  1.0        1\n",
       "7031  (1.9999458781640924, 2.001082630964643, 2.1851...  0.0        0\n",
       "\n",
       "[7032 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.select(['X_scaled','Y','Outputs']).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator(predictionCol='Outputs',featuresCol='X_scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.24929932328548837\n"
     ]
    }
   ],
   "source": [
    "silhouette = evaluator.evaluate(preds)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[1.00392228 0.65833406 1.45160513 3.11604072 0.42285439 1.43695546\n",
      " 1.3022817  0.74426218 0.98019737 1.1275893  0.68357414 1.39000141\n",
      " 0.57600312 1.50319652 0.89811073 1.21396486 0.46281749 1.5895718\n",
      " 0.4579534  1.59221335 0.63915621 0.88910412 1.43393269 0.69462567\n",
      " 0.1694083  0.75211134 0.58784919 2.10415046 3.0170633  2.06304207]\n",
      "[1.01241705 1.24778619 1.57866747 3.02239915 1.26745663 0.52641988\n",
      " 0.65307452 0.71167763 1.00261001 0.35580697 0.9976055  0.35155099\n",
      " 1.06092773 0.28536346 1.03778525 0.31582231 1.01397345 0.34031017\n",
      " 1.00615997 0.34923573 1.37151543 0.3768938  1.07818021 0.72148342\n",
      " 0.7540903  0.4049286  0.35727239 0.88018806 1.66802053 0.41325648]\n"
     ]
    }
   ],
   "source": [
    "# Shows the result.\n",
    "centers = modelo.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios:\n",
    "\n",
    "    1. A partir de los sparce vectors regenerar el vector con toda la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "listSpareVec = df2.select(['X_scaled']).toPandas().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOriginVec=[]\n",
    "\n",
    "for vector in listSpareVec:\n",
    "    listOriginVec.append(np.array(vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.        , 0.        , 2.1851749 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 2.10555512, 1.99988699, 0.        ,\n",
       "        0.        , 2.1036961 , 2.01441974, 0.        , 2.0000144 ,\n",
       "        0.        , 2.04155728, 0.        , 2.04504059, 0.        ,\n",
       "        2.01036463, 0.        , 2.03515559, 2.11647677, 0.        ,\n",
       "        0.        , 0.        , 0.04074106, 0.99215668, 0.01316851]),\n",
       " array([1.99994588, 2.00108263, 2.1851749 , 3.38328263, 2.00124731,\n",
       "        0.        , 0.        , 2.10555512, 0.        , 2.21150744,\n",
       "        2.01491236, 0.        , 0.        , 2.10514026, 2.0000144 ,\n",
       "        0.        , 2.04155728, 0.        , 2.04504059, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 2.38301008,\n",
       "        0.        , 0.        , 1.38519618, 1.89290864, 0.83356444]),\n",
       " array([1.99994588, 2.00108263, 2.1851749 , 3.38328263, 2.00124731,\n",
       "        0.        , 0.        , 2.10555512, 0.        , 2.21150744,\n",
       "        0.        , 2.1036961 , 2.01441974, 0.        , 2.0000144 ,\n",
       "        0.        , 2.04155728, 0.        , 2.04504059, 0.        ,\n",
       "        2.01036463, 0.        , 2.03515559, 0.        , 2.38301008,\n",
       "        0.        , 0.        , 0.08148213, 1.7898706 , 0.04771103]),\n",
       " array([1.99994588, 2.00108263, 2.1851749 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 2.10555512, 0.        , 2.21150744,\n",
       "        2.01491236, 0.        , 0.        , 2.10514026, 0.        ,\n",
       "        2.20341148, 2.04155728, 0.        , 2.04504059, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        2.41668263, 0.        , 1.83334789, 1.40597077, 0.81205808])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOriginVec[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Calcular accuracy en el clasificador logistic regression (sklearn.metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_real = predictions.select(['Y']).toPandas().values\n",
    "Y_predicha = predictions.select(['prediction']).toPandas().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7955840455840456"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_real,Y_predicha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
